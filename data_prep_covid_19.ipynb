{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Covid Data Prep</h1>\n",
    "<h3>Feature Engineering</h3>\n",
    "<p>The notebook below takes the Covid-19 df and prepares it to use in XGBoost and Deep Learning Notebooks</p>\n",
    "<br>\n",
    "<p>The raw data consists of the following feature</p>\n",
    "<ol>\n",
    "    <li>dateRep</li>\n",
    "    <li style=\"color:red;\">day</li>\n",
    "    <li style=\"color:red;\">month</li>\n",
    "    <li style=\"color:red;\">year</li>\n",
    "    <li>cases</li>\n",
    "    <li>deaths</li>\n",
    "    <li>countriesAndTerritories</li>\n",
    "    <li style=\"color:red;\">geoId</li>\n",
    "    <li style=\"color:red;\">countryterritorycode</li>\n",
    "    <li>popData2018</li>\n",
    "    <li style=\"color:red;\">continentExp</li>\n",
    "</ol>\n",
    "<br>\n",
    "</p>Feature names in red will be remove as they were defined as adding little information to the model. The remaining feautures will be evaluated through the notebook below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import dependancies</h5>\n",
    "<ul>\n",
    "    <li>pandas: feature extrapolation and extraction and creation</li>\n",
    "    <li>numpy: numerical data manipluation</li>\n",
    "    <li>os: interaction with the operating system</li>\n",
    "    <li>seaborn: plotting library</li>\n",
    "    <li>sklearn.model_selection.train_test_split: spliting the data into the various data sets (train, test and validation)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</h2>Read in raw data</h2>\n",
    "\n",
    "<p>Change to the relevant directory and read in the csv</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv will need some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.getcwd(), 'Datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now read the file. No Line should need skipping.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateRep</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>countriesAndTerritories</th>\n",
       "      <th>geoId</th>\n",
       "      <th>countryterritoryCode</th>\n",
       "      <th>popData2018</th>\n",
       "      <th>continentExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/05/2020</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/05/2020</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>168</td>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>37172386.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dateRep  day  month  year  cases  deaths countriesAndTerritories geoId  \\\n",
       "0  08/05/2020    8      5  2020    171       2             Afghanistan    AF   \n",
       "1  07/05/2020    7      5  2020    168       9             Afghanistan    AF   \n",
       "\n",
       "  countryterritoryCode  popData2018 continentExp  \n",
       "0                  AFG   37172386.0         Asia  \n",
       "1                  AFG   37172386.0         Asia  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and format dataframe\n",
    "covid19_df = pd.read_csv(os.path.join(data_folder, 'COVID-19-geographic-disbtribution-worldwide-2020-05-08.csv'), engine='python')\n",
    "covid19_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "drop_columns = ['geoId', 'day', 'month', 'year', 'countryterritoryCode', 'continentExp']\n",
    "# Create a 'datetime' column based on the dates\n",
    "covid19_df['dateRep'] = pd.to_datetime(covid19_df['dateRep'], dayfirst=True)\n",
    "# Drop the columns that add no value\n",
    "covid19_df.drop(columns=drop_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the table by the date\n",
    "covid19_df.sort_values(by=['dateRep'], ascending=True, inplace=True)\n",
    "# Create a cumulative sum of covid cases and deaths\n",
    "covid19_df['Cum_Cases'] = covid19_df.groupby(\"countriesAndTerritories\")['cases'].cumsum()\n",
    "covid19_df['Cum_Deaths'] = covid19_df.groupby(\"countriesAndTerritories\")['deaths'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for days since x deaths\n",
    "covid19_df['flag'] = np.where(covid19_df['Cum_Cases'] > 100, 1, 0) # calculate globaly as its a true false\n",
    "# groupby again creating a unique dataframe for each country, and applying a cumulative sum to the \"flag\" column\n",
    "covid19_df['flag'] = covid19_df.loc[covid19_df['Cum_Cases'] > 100].groupby(\"countriesAndTerritories\")['flag'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We don't want Nan's so we replace them in the next few cells below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateRep : 0.0\n",
      "cases : 0.0\n",
      "deaths : 0.0\n",
      "countriesAndTerritories : 0.0\n",
      "popData2018 : 0.011211619314562365\n",
      "Cum_Cases : 0.0\n",
      "Cum_Deaths : 0.0\n",
      "flag : 0.5729392279271245\n"
     ]
    }
   ],
   "source": [
    "for i in covid19_df.columns:\n",
    "    frac_null = covid19_df[i].isna().sum() /len(covid19_df)\n",
    "    print(i, ':', frac_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United_States_of_America', 'United_Kingdom', 'Italy', 'Spain']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_count = covid19_df.groupby('countriesAndTerritories')['deaths'].sum().sort_values(ascending=False).iloc[:20]\n",
    "top_count = list(top_count.keys())\n",
    "top_count[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15698"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid19_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataframe to just the 20 most affected countries\n",
    "covid19_df = covid19_df[covid19_df['countriesAndTerritories'].isin(top_count)]\n",
    "# Fill the empty 'flag' rows\n",
    "covid19_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2443"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid19_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Above we filtered out countries not in the 'top_count' list</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Below we export the .csv as a master dataframe. We then do the final processing stages for the train and test datasets</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the folder 'data_export' exists and if not create it.\n",
    "folder_create = os.path.exists(os.path.join(data_folder, \"data_export\"))\n",
    "if folder_create is False:\n",
    "    os.mkdir(os.path.join(data_folder, \"data_export\"))\n",
    "# Export the polished dataframe to re-import after modelling.\n",
    "covid19_df.to_csv(os.path.join(data_folder, \"data_export\", \"covid19_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'get_dummies' creates a new column for each country that is populated with either a 1 or a 0\n",
    "df_train = pd.get_dummies(data=covid19_df, columns=[\"countriesAndTerritories\"])\n",
    "# df_y is target to predict, in this case 'deaths'\n",
    "df_y = df_train[['deaths', 'dateRep']]\n",
    "# df_train contains the columns we will use to predict 'deaths'\n",
    "df_train.drop(columns=['cases', 'deaths', 'Cum_Cases', 'Cum_Deaths'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_folder, \"data\")\n",
    "# Check if the 'data' folder exists, if not create it\n",
    "folder_create = os.path.exists(data_path)\n",
    "if folder_create is False:\n",
    "    os.mkdir(data_path)\n",
    "    # Create 'train' and 'test' folders if the data folder does not exist.\n",
    "    os.mkdir(os.path.join(data_path, \"train\"))\n",
    "    os.mkdir(os.path.join(data_path, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of randomly splitting the data we will select a date to test 'blind' from\n",
    "date_slice = '2020-04-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split according to the date. 'train'=before date, 'test'=after.\n",
    "X_train = df_train.loc[df_train['dateRep'] < date_slice]\n",
    "X_test = df_train.loc[df_train['dateRep'] >= date_slice]\n",
    "y_train = df_y.loc[df_y['dateRep'] < date_slice]\n",
    "y_test = df_y.loc[df_y['dateRep'] >= date_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export these four dataframes for later.\n",
    "X_train.to_csv(os.path.join(data_path, \"train\", \"train_x.csv\"))\n",
    "y_train.to_csv(os.path.join(data_path, \"train\", \"train_y.csv\"))\n",
    "X_test.to_csv(os.path.join(data_path, \"test\", \"test_x.csv\"))\n",
    "y_test.to_csv(os.path.join(data_path, \"test\", \"test_y.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
